%\documentclass[12pt,a4paper]{report}
\documentclass[12pt,a4paper]{article}

\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx,url}
\usepackage{hyperref}
%\usepackage{mathptmx}
\usepackage{lipsum}
\usepackage{booktabs}
\usepackage{pifont}
\usepackage{textcomp}
\usepackage{amsmath,amssymb}
\usepackage{listings}
\usepackage[scaled=0.8]{beramono}
\usepackage{xspace}

\pdfgentounicode=1

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\begin{document}

\input{./cover.tex}

\section{Introdução}
Este relatório tem como objetivo apresentar os resultados obtidos a partir da
execução do segundo exercício de programação paralela~\cite{exercise}, que
consiste na paralelização do algoritmo \emph{Pi de Monte Carlo} utilizando a
biblioteca \texttt{pthreads}. Primeiramente, os aspectos principais do
algoritmo desenvolvido e a estratégia de paralelização utilizada é apresentada.
Em seguida, é realizada uma análise de desempenho comparando os tempos de
execução do algoritmo em diversas configurações, isto é, variando-se o número
de lançamentos (pontos) e o número de \textit{threads}.  O código-fonte
completo deste trabalho (incluindo os arquivos \LaTeX\xspace que compõem este
relatório) estão publicamente disponíveis no
GitHub~\footnote{\url{https://github.com/alexandrelucchesi/parallel-programming-ex02}}.

\subsection{\textit{Hardware} Utilizado}
\label{sec:hardware}

\begin{itemize}
    \item Processador: Intel Core i7
    \item Velocidade: 2 GHz
    \item Número de processadores: 1
    \item Número de \textit{cores} reais: 2
    \item Número de \textit{cores} virtuais: 4 (HyperThreading)
    \item L1 cache: 32KB
    \item L2 cache (per core): 256KB
    \item L3 cache: 4MB
\end{itemize}


\section{O Algoritmo}
Além do programa principal, foi desenvolvido um \textit{script bash} para
automatizar os testes da aplicação. Esses artefatos são descritos a seguir.

\begin{itemize}
	\item \texttt{main.c}: programa em C contendo o código-fonte da aplicação. Após compilado com as respectivas diretivas
		(\texttt{-lpthread -lmath} --- vide Makefile) recebe via
		\texttt{scanf()} dois argumentos: o número de \textit{threads} a serem
		criadas e a quantidade de lançamentos a serem realizados. A saída do
		programa tem duas linhas: a primeira contém o valor aproximado de Pi e
		a segunda, o tempo de execução do algoritmo em microsegundos.
	\item \texttt{test.sh}: \textit{script} desenvolvido para automatizar os
		testes da aplicação. Recebe como entrada 4 argumentos, em ordem:
		\begin{itemize}
			\item \texttt{max\_threads}: número máximo de \textit{threads}. O
				\textit{script} varia o número de \textit{threads} de 1 até
				\texttt{max\_threads}.
			\item \texttt{max\_tosses}: ordem máxima do número de lançamentos, isto
				é, o \textit{script} executa a aplicação variando o 
				número de lançamentos, começando em $10^2, 10^3$ até $10^{max\_tosses}$.
			\item \texttt{max\_count}: número máximo de vezes em que o programa
				deve ser executado em uma mesma configuração.
			\item \texttt{max\_time}: \textit{timeout} de execução, ou seja, se o
				programa não encerrar a execução nesse tempo, ele é finalizado.
		\end{itemize}
\end{itemize}

\subsection{Geração de números aleatórios}
Como o método de aproximação do valor de pi é baseado no Método de Monte Carlo,
é necessária a geração de números aleatórios de ponto-flutuante. Além disso, a
função que gera esses números tem que ser \textit{thread safe}, uma vez que o
algoritmo sera paralelizado e o código chamado por várias \textit{threads} ao
mesmo tempo. Por isso, utilizou-se a função \texttt{rand\_r(unsigned int *)}.

A função inicializadora, \texttt{srand(unsigned int seed)}, foi executada uma
vez por \textit{thread}. Inicialmente, utilizou-se como semente para
\texttt{srand} o resultado de uma função temporal (\texttt{time(NULL)}), porém,
os resultados de pi em múltiplas execuções do programa quando executado a
partir do \textit{script} estava igual. Acredita-se que isso se deve ao fato
das várias execuções serem realizadas em um intervalo de tempo muito pequeno,
pois, acrescentando-se um \texttt{sleep(1)} entre as chamadas, os resultados
começaram a variar.

Apesar de correta, a solução com \texttt{sleep()} não é ideal, pois deixa a
execução dos testes muito lenta, sobretudo se o conjunto de testes for
abrangente (vide Seção X). Dessa forma, somou-se ao resultado de
\textit{time(NULL)} um fator para introduzir aleatoridade que é único entre
várias execuções do programa: o valor de \texttt{getpid()}.

\subsection{Política de escalonamento}
Procurou-se similar a política de escalonamento estática encontrada na
biblioteca OpenMP.  Dessa forma, tenta-se dividir igualmente o trabalho entre
as \textit{threads} antes da criação ou execução das mesmas. Por exemplo, se a
entrada do programa for 2 \textit{threads} e 1000 lançamentos, atribui-se
previamente a cada \textit{thread} o cálculo de 500 lançamentos. Caso a divisão
não seja exata, ou seja, se a entrada do programa for 2 \textit{threads} e 1005
lançamentos, o excedente (resto da divisão) é atribuído à primeira
\textit{thread} criada.


\subsection{Parâmetros de entrada}
Se o número de \textit{threads} especificado for menor ou igual a 1, nenhuma
\textit{thread} é criada e o programa é executado de forma sequencial. É válido
ressaltar que isso não implicou em redundância de código-fonte, ou seja, no
\emph{modo sequencial} é executada a mesma função cujo ponteiro seria passado
para \texttt{pthread\_create()}, porém, sem o \textit{overhead} de criação e
finalização de \textit{threads}.


\subsection{Tipos das variáveis}
Com o objetivo de se preservar ao máximo os dados provenientes das computações
e mitigar a perda de precisão por truncamento ou resultados errôneos por
\textit{overflow}, usou-se em toda a aplicação os tipos \texttt{unsigned long
long int} e \texttt{long long int} para valores inteiros, e \texttt{long
double} para valores de ponto flutuante. Utilizou-se \texttt{typedef}s para tornar o código menos verboso e mais 
legível:

\begin{verbatim}
typedef unsigned long long int ulli;
\end{verbatim}


\subsection{\textit{Benchmark}}
O \textit{benchmarking} da aplicação foi feito a partir de uma série de funções,
cujas assinaturas são apresentadas a seguir:

\begin{verbatim}
int bench(const char* filename);
bench_res* bench_sched_chunk(const char *filename, int power_of_2);
bench_res* bench_sched_thread(const char *filename, int chunk_size,
    int max_threads);
double calculate_mean(const double *vec, int size);
void write_csv(bench_res *res, benchType type, int size, FILE *fp);
void write_latex_tables(bench_res *res, benchType type, int size,
    FILE *fp);
\end{verbatim}

A função \texttt{bench} é responsável por orquestrar as funções
\texttt{bench\_sched\_chunk} e \texttt{bench\_sched\_thread} na geração dos
relatórios contendo os tempos de execução do algoritmo em diferentes
configurações. Essas funções realizam dois tipos diferentes de
\textit{benchmarking}: a primeira varia o tamanho do \textit{chunk} e as
políticas de escalonamento enquanto mantém o número de \textit{threads}
fixo~\footnote{Esse valor é o valor padrão atribuído pelo OpenMP de acordo com a
máquina que está executando o algoritmo. No \textit{hardware} utilizado neste
trabalho, este valor padrão é 4, uma vez que o processador possui 2
\textit{cores} em HyperThreading.}; já a segunda mantém o tamanho do
\textit{chunk} fixo~\footnote{Adotou-se o valor do \textit{chunk} como sendo
256, que foi o valor ótimo obtido a partir do primeiro experimento (vide
Tabela~\ref{table:bench-sched-chunk}).} enquanto varia as políticas de
escalonamento e o número de \textit{threads}. Ambas retornam uma lista de
\texttt{bench\_res}, que é uma estrutura de dados que encapsula as informações
necessárias para a geração do relatório, definida como:

\begin{verbatim}
typedef struct bench_res {
    int chunk_size;
    double static_sorting_time;
    double static_input_sorting_time;
    double dynamic_sorting_time;
    double dynamic_input_sorting_time;
    double guided_sorting_time;
    double guided_input_sorting_time;
} bench_res;
\end{verbatim}

Essas funções utilizam internamente 3 funções auxiliares:
\texttt{calculate\_mean}, \texttt{write\_csv} e \texttt{write\_latex\_tables}. A
primeira é utilizada para se calcular o tempo médio de execução em cada
configuração de entrada da função \texttt{count\_sort}, recebendo um vetor de
tempos de execução (representados como \texttt{double}) e calculando a média
aritmética desses valores~\footnote{A quantidade de vezes que
\texttt{count\_sort} deve ser executada por configuração é configurada a partir
da diretiva \texttt{\#define BENCH\_EXEC\_TIMES N}, onde N é o número de
execuções}. As duas últimas são mecanismos de exportação dos resultados,
representando-os no formato CSV ou como um conjunto de tabelas prontas para
serem importadas em um arquivo \texttt{.tex} (vide
Tabelas~\ref{table:bench-sched-chunk} e~\ref{table:bench-sched-thread}).
 
\section{Resultados}
Conforme explicado na seção anterior, foram gerados dois tipos de
\textit{benchmark}: um para avaliar o desempenho variando o tamanho do
\textit{chunk} e outro para avaliar o desempenho variando o número de
\textit{threads}. Como entrada para o algoritmo, utilizou-se um arquivo contendo
32768 números de ponto-flutante gerados a partir do método descrito na
Seção~\ref{sec:data-gen}. Além disso, para cada conjunto de entradas,
executou-se o algoritmo 3 vezes e calculou-se a média aritmética dos tempos de
execução, a fim de se obter medidas mais precisas. O teste foi realizado
executando a aplicação com a \textit{flag} \texttt{-bench}, que demorou
2961.464582s para executar e forneceu como saída dois arquivos:
\texttt{bench\_sched\_chunk.tex} e \texttt{bench\_sched\_thread.tex} ---
contendo os resultados dos testes.

%\begin{verbatim}
%$ ./a.out -bench vec.dat
%===================================================================
%Benchmarking: varying chunk size and scheduling policy
%===================================================================
%Looping...
%Performing iteration 0, chunk size is 1.
%Performing iteration 1, chunk size is 2.
%Performing iteration 2, chunk size is 4.
%Performing iteration 3, chunk size is 8.
%Performing iteration 4, chunk size is 16.
%Performing iteration 5, chunk size is 32.
%Performing iteration 6, chunk size is 64.
%Performing iteration 7, chunk size is 128.
%Performing iteration 8, chunk size is 256.
%Performing iteration 9, chunk size is 512.
%Performing iteration 10, chunk size is 1024.
%Performing iteration 11, chunk size is 2048.
%Performing iteration 12, chunk size is 4096.
%Performing iteration 13, chunk size is 8192.
%Performing iteration 14, chunk size is 16384.
%Performing iteration 15, chunk size is 32768.
%Performing iteration 16, chunk size is 65536.
%Generating output latex tables...
%File 'bench_sched_chunk.tex' successfully generated! :-)
%
%===================================================================
%Benchmarking: varying thread count and scheduling policy
%===================================================================
%Looping...
%Performing iteration 0, thread count is 1.
%Performing iteration 1, thread count is 2.
%Performing iteration 2, thread count is 3.
%Performing iteration 3, thread count is 4.
%Performing iteration 4, thread count is 5.
%Performing iteration 5, thread count is 6.
%Performing iteration 6, thread count is 7.
%Performing iteration 7, thread count is 8.
%Generating output latex tables...
%File 'bench_sched_thread.tex' successfully generated! :-)
%
%Execution time: 2961.464582 seconds.
%\end{verbatim}

A Tabela~\ref{table:bench-sched-chunk} apresenta os resultados da primeira
análise. Nota-se que em todos os casos, o tamanho de \textit{chunk} ótimo foi
1.  Isso contrariou as expectativas, pois esperava-se obter como tamanho ótimo
para o \textit{chunk} um valor que se aproximasse do tamanho da \textit{cache},
para se beneficiar do \emph{alinhamento de cache}~\cite{class-notes}. Além
disso, observa-se que o escalonamento estático apresenta desempenho médio
superior ao dinâmico e ao guiado, e que o impacto de desempenho provocado pela
leitura dos dados é irrisório, sendo em média inferior à 0.1s.

\begin{table}[h!]
\footnotesize
\centering
\caption{Tamanho de \textit{chunk} variável e número de \textit{threads} fixo (em 4).}
\label{table:bench-sched-chunk}
\input{./bench_sched_chunk.tex}
\end{table}

A Tabela~\ref{table:bench-sched-thread} apresenta os resultados da segunda
análise. Observa-se dois valores aparentemente absurdos de tempo de resposta com
escalonamento dinâmico e uma \textit{thread}: 680.678471s e 680.679593s. No
entanto, esses valores apareceram nos resultados porque o \textit{laptop}
``dormiu'' devido à inatividade enquanto executava o algoritmo.

\begin{table}[h!]
\footnotesize
\centering
\caption{Tamanho de \textit{chunk} fixo (em 256) e número de \textit{threads}
variável.}
\label{table:bench-sched-thread}
\input{./bench_sched_thread.tex}
\end{table}

O \textit{speedup} de um programa paralelo é definido como~\cite{main-book}:

$$S = \frac{T_{serial}}{T_{parallel}}$$

Por motivos de simplificação, a Tabela~\ref{table:speedup} apresenta a relação
entre o \textit{speedup} obtido e o número de \textit{threads} executadas apenas
para o escalonamento estático, uma vez que as outras políticas apresentaram
ganhos similares. Observa-se que ao se utilizar duas \textit{threads} foi
possível obter um ganho significativo de desempenho ($\approx 72\%$). A partir
de três \textit{threads} o ganho sofreu atenuação e manteve uma certa
uniformidade. Acredita-se que esse comportamento ocorreu devido as
características do processador utilizado (vide Seção~\ref{sec:hardware}), que só
possui 2
\textit{cores}.

\begin{table}[h!]
\footnotesize
\centering
\caption{\textit{Speedup} x \textit{threads}.}
\label{table:speedup}
\begin{tabular}{@{}cccccccc@{}}
\toprule
\textit{Threads} & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\ \midrule
\textit{Speedup} & 0.717707 & 0.548823 & 0.564227 & 0.573196 & 0.580434 & 0.567042 & 0.581778 \\ \bottomrule 
\end{tabular}
\end{table}


\section{Conclusão}
Este trabalho possibilitou uma maior compreensão acerca da biblioteca OpenMP e
sobre algumas das dificuldades encontradas no contexto de programação paralela.
O algoritmo \textit{count sort} foi otimizado a partir da aplicação de técnicas
de programação para um maior aproveitamento dos recursos computacionais que
levaram a ganhos de desempenho. Uma análise dos tempos de execução do algoritmo
evidenciou ganhos de desempenho (\textit{speedup}) de até 72\% em relação à
versão sequencial.

Por fim, é válido ressaltar que o programa está todo parametrizado via diretivas
de pré-processamento (\texttt{\#define}) e aceita parâmetros de configuração em
tempo de execução, possibilitando a experimentação com diferentes entradas para
o algoritmo. Além disso, o \textit{design} da aplicação permite variar de forma
fácil a política de escalonamento, o tamanho dos \textit{chunks} e a quantidade
de \textit{threads} a serem executadas de forma não intrusiva, e favorece a
inclusão de novas funções de \textit{benchmarking} de forma modular.

\bibliographystyle{plain}
\bibliography{references.bib}

\end{document}








