%\documentclass[12pt,a4paper]{report}
\documentclass[12pt,a4paper]{article}

\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx,url}
\usepackage{hyperref}
%\usepackage{mathptmx}
\usepackage{lipsum}
\usepackage{booktabs}
\usepackage{pifont}
\usepackage{textcomp}
\usepackage{amsmath,amssymb}
\usepackage{listings}
\usepackage[scaled=0.8]{beramono}
\usepackage{xspace}

\pdfgentounicode=1

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\begin{document}

\input{./cover.tex}

\section{Introdução}
Este relatório tem como objetivo apresentar os resultados obtidos a partir da
execução do primeiro exercício de programação paralela~\cite{exercise}, que
consiste na paralelização do algoritmo \emph{count sort} utilizando a
biblioteca OpenMP\@.  Primeiramente, o algoritmo desenvolvido e a estratégia de
paralelização utilizada é apresentada. Em seguida, é feita uma análise de
desempenho comparando os tempos de execução do algoritmo em diversas
configurações, isto é, variando-se a estratégia de escalonamento, o tamanho dos
\textit{chunks} e o número de \textit{threads}. O código-fonte completo deste
trabalho (incluindo os arquivos \LaTeX\xspace que compõem este relatório) estão
publicamente disponíveis no
GitHub~\footnote{\url{https://github.com/alexandrelucchesi/parallel-programming-ex01}}.

\subsection{\textit{Hardware} Utilizado}
\label{sec:hardware}

\begin{itemize}
    \item Processador: Intel Core i7
    \item Velocidade: 2 GHz
    \item Número de processadores: 1
    \item Número de \textit{cores} reais: 2
    \item Número de \textit{cores} virtuais: 4 (HyperThreading)
    \item L1 cache: 32KB
    \item L2 cache (per core): 256KB
    \item L3 cache: 4MB
\end{itemize}


\section{O Algoritmo}
O programa desenvolvido contempla três funcionalidades principais: geração de um
arquivo de dados contendo um número arbitrário de valores de ponto-flutuante,
processamento de um único arquivo de dados e a geração de um \textit{benchmark}.
Essas três funcionalidades são detalhadas nesta seção.

\subsection{Geração do Arquivo de Dados}
\label{sec:data-gen}
O \textit{count sort} é um algoritmo de ordenação que foi utilizado neste
trabalho para ordenar um vetor de números de ponto-flutuante. Dessa forma, foi
necessária a criação de funções para a geração de quantidades configuráveis de
números de ponto-flutante em um formato apropriado para servir de entrada para o
programa, possibilitando a fácil experimentação do \textit{count sort} com
diferentes configurações.

A interface dessas funções é apresentada a seguir:

\begin{verbatim}
void generate_floats(FILE* out, int count);
int read_input(FILE* fp, float** vector, int* size);
float* parse_floats(char* values_str, int count);
\end{verbatim}

A função \texttt{generate\_floats} recebe um arquivo de destino e a quantidade de
números que se deseja gerar. A função \texttt{read\_input} recebe um arquivo (no
formato gerado por \texttt{generate\_floats}) e retorna em \texttt{vector} e
\texttt{size} o vetor e seu tamanho, respectivamente. Por fim, a função
\texttt{parse\_floats} é utilizada internamente por \texttt{read\_input} para
realizar o \textit{parsing} de \textit{strings} para \textit{floats}.

Para gerar um arquivo de dados, \texttt{vec.dat}, contendo, por exemplo, 1000
elementos, basta executar o binário passando-se a \textit{flag} \texttt{-gen},
conforme descrito a seguir:

\begin{verbatim}
$ ./a.out -gen vec.dat 1000
\end{verbatim}

\subsection{Processamento}
O processamento de um arquivo de dados foi encapsulado na função
\texttt{process}, cuja assinatura é apresentada a seguir:

\begin{verbatim}
int process(float **vec, int *vec_size, double *time_sorting_only,
    double*time_with_input, const char *filename, omp_sched_t kind,
    int chunk_size, int thread_num);
void count_sort(float a[], int n,
    omp_sched_t kind, int chunk_size, int thread_num);
\end{verbatim}

Os quatro primeiros parâmetros: \texttt{vec}, \texttt{vec\_size},
\texttt{time\_sorting\_only} e \texttt{time\_with\_input} são, na verdade, retornos
da função \texttt{process}, e retornam respectivamente, o vetor de
\textit{floats} ordenado, o tamanho do vetor, o tempo transcorrido considerando
apenas a execução do \textit{count sort} e o tempo transcorrido desde a entrada
de dados até o término da execução da função de ordenação. Os demais parâmetros
são utilizados para parametrizar a execução da função \texttt{count\_sort} e
equivalem, respectivamente, ao nome do arquivo de dados, à política de
escalonamento do OpenMP (\textit{static}, \textit{dynamic}, \textit{guided} ou
\textit{auto}), ao tamanho do \textit{chunk} e ao número de \textit{threads} a
serem criadas.

Para processar um único arquivo, basta executar o binário passando-se o arquivo
de dados e \textit{flags} opcionais de seleção da política de escalonamento,
tamanho do \textit{chunk} ou quantidade de \textit{threads}. Por padrão,
utiliza-se \texttt{static}, tamanho do \textit{chunk} 1 e o número padrão de
\textit{threads} do OpenMP (depende da máquina sendo executada). O trecho
abaixo ilustra o processamento do arquivo \texttt{vec.dat}, com escalonamento
dinâmico e tamanho de \textit{chunk} 4:

\begin{verbatim}
$ ./a.out vec.dat -k dynamic -c 4
\end{verbatim}

Encapsular a lógica de processamento na função \textit{process} permitiu a
automatização do \textit{benchmarking} da aplicação, por meio do desenvolvimento
da função \texttt{bench} (apresentada na próxima seção), evitando trabalho
manual.

A função \texttt{count\_sort} é a principal função da aplicação. Um dos
objetivos deste trabalho consistiu na experimentação da biblioteca OpenMP\@. O
trecho de código a seguir apresenta o núcleo da função \texttt{count\_sort} e a
estratégia de paralelização adotada:

\begin{verbatim}
...
    // Set number of threads to be created.
    if (num_threads > 0) omp_set_num_threads(num_threads);
#pragma omp parallel
    {
        int count; // *Private* variable.

        // Set scheduling policy and chunk size at runtime.
        omp_set_schedule(kind, chunk_size);

#pragma omp for schedule(runtime)
        for (int i = 0; i < n; i++) {
            count = 0;
            for (int j = 0; j < n; j++)
                if (a[j] < a[i])
                    count++;
                else if (a[j] == a[i] && j < i)
                    count++;
            temp[count] = a[i];
        }
    }
...
\end{verbatim}

A variável \texttt{count} é declarada dentro de uma seção paralela e, portanto,
é atribuída um escopo privado~\footnote{Poderia-se declarar esse escopo via
\textit{clauses} dentro do \texttt{pragma}.}. As funções
\texttt{omp\_set\_num\_threads} e \texttt{omp\_set\_schedule} são padrões do
OpenMP e consistem em uma forma dinâmica de se configurar, respectivamente, a
quantidade de \textit{threads}, e a política de escalonamento e o tamanho do
\textit{chunk}. Esses parâmetros são utilizados em tempo de execução para
atribuir tarefas às \textit{threads} dentro do \texttt{for} (observe a
\textit{clause} \texttt{schedule(runtime)}). O vetor \texttt{temp} é uma
variável compartilhada que, no término das iterações, contém a sequência de
números ordenada. É importante notar que nenhum mecanismo de sincronização (como
a utilização de \textit{locks} ou declarar \texttt{temp} como \emph{critical})
foi necessário para a criação de uma seção crítica em torno de \texttt{temp},
uma vez que \texttt{count} retorna um valor diferente (indexando uma posição de
memória diferente) para cada \textit{thread} e, portanto, não há condições de
corrida.


\subsection{\textit{Benchmark}}
O \textit{benchmarking} da aplicação foi feito a partir de uma série de funções,
cujas assinaturas são apresentadas a seguir:

\begin{verbatim}
int bench(const char* filename);
bench_res* bench_sched_chunk(const char *filename, int power_of_2);
bench_res* bench_sched_thread(const char *filename, int chunk_size,
    int max_threads);
double calculate_mean(const double *vec, int size);
void write_csv(bench_res *res, benchType type, int size, FILE *fp);
void write_latex_tables(bench_res *res, benchType type, int size, FILE *fp);
\end{verbatim}

A função \texttt{bench} é responsável por orquestrar as funções
\texttt{bench\_sched\_chunk} e \texttt{bench\_sched\_thread} na geração dos
relatórios contendo os tempos de execução do algoritmo em diferentes
configurações. Essas funções realizam dois tipos diferentes de
\textit{benchmarking}: a primeira varia o tamanho do \textit{chunk} e as
políticas de escalonamento enquanto mantém o número de \textit{threads}
fixo~\footnote{Esse valor é o valor padrão atribuído pelo OpenMP de acordo com a
máquina que está executando o algoritmo. No \textit{hardware} utilizado neste
trabalho, este valor padrão é 4, uma vez que o processador possui 2
\textit{cores} em HyperThreading.}; já a segunda mantém o tamanho do
\textit{chunk} fixo~\footnote{Adotou-se o valor do \textit{chunk} como sendo
256, que foi o valor ótimo obtido a partir do primeiro experimento (vide
Tabela~\ref{table:bench-sched-chunk}).} enquanto varia as políticas de
escalonamento e o número de \textit{threads}. Ambas retornam uma lista de
\texttt{bench\_res}, que é uma estrutura de dados que encapsula as informações
necessárias para a geração do relatório, definida como:

\begin{verbatim}
typedef struct bench_res {
    int chunk_size;
    double static_sorting_time;
    double static_input_sorting_time;
    double dynamic_sorting_time;
    double dynamic_input_sorting_time;
    double guided_sorting_time;
    double guided_input_sorting_time;
} bench_res;
\end{verbatim}

Essas funções utilizam internamente 3 funções auxiliares:
\texttt{calculate\_mean}, \texttt{write\_csv} e \texttt{write\_latex\_tables}. A
primeira é utilizada para se calcular o tempo médio de execução em cada
configuração de entrada da função \texttt{count\_sort}, recebendo um vetor de
tempos de execução (representados como \texttt{double}) e calculando a média
aritmética desses valores~\footnote{A quantidade de vezes que
\texttt{count\_sort} deve ser executada por configuração é configurada a partir
da diretiva \texttt{\#define BENCH\_EXEC\_TIMES N}, onde N é o número de
execuções}. As duas últimas são mecanismos de exportação dos resultados,
representando-os no formato CSV ou como um conjunto de tabelas prontas para
serem importadas em um arquivo \texttt{.tex} (vide
Tabelas~\ref{table:bench-sched-chunk} e~\ref{table:bench-sched-thread}).
 
\section{Resultados}
Conforme explicado na seção anterior, foram gerados dois tipos de
\textit{benchmark}: um para avaliar o desempenho variando o tamanho do
\textit{chunk} e outro para avaliar o desempenho variando o número de
\textit{threads}. Como entrada para o algoritmo, utilizou-se um arquivo contendo
32768 números de ponto-flutante gerados a partir do método descrito na
Seção~\ref{sec:data-gen}. Além disso, para cada conjunto de entradas,
executou-se o algoritmo 3 vezes e calculou-se a média aritmética dos tempos de
execução, a fim de se obter medidas mais precisas. O teste foi realizado
executando a aplicação com a \textit{flag} \texttt{-bench}, que demorou
2961.464582s para executar e forneceu como saída dois arquivos:
\texttt{bench\_sched\_chunk.tex} e \texttt{bench\_sched\_thread.tex} ---
contendo os resultados dos testes.

%\begin{verbatim}
%$ ./a.out -bench vec.dat
%===================================================================
%Benchmarking: varying chunk size and scheduling policy
%===================================================================
%Looping...
%Performing iteration 0, chunk size is 1.
%Performing iteration 1, chunk size is 2.
%Performing iteration 2, chunk size is 4.
%Performing iteration 3, chunk size is 8.
%Performing iteration 4, chunk size is 16.
%Performing iteration 5, chunk size is 32.
%Performing iteration 6, chunk size is 64.
%Performing iteration 7, chunk size is 128.
%Performing iteration 8, chunk size is 256.
%Performing iteration 9, chunk size is 512.
%Performing iteration 10, chunk size is 1024.
%Performing iteration 11, chunk size is 2048.
%Performing iteration 12, chunk size is 4096.
%Performing iteration 13, chunk size is 8192.
%Performing iteration 14, chunk size is 16384.
%Performing iteration 15, chunk size is 32768.
%Performing iteration 16, chunk size is 65536.
%Generating output latex tables...
%File 'bench_sched_chunk.tex' successfully generated! :-)
%
%===================================================================
%Benchmarking: varying thread count and scheduling policy
%===================================================================
%Looping...
%Performing iteration 0, thread count is 1.
%Performing iteration 1, thread count is 2.
%Performing iteration 2, thread count is 3.
%Performing iteration 3, thread count is 4.
%Performing iteration 4, thread count is 5.
%Performing iteration 5, thread count is 6.
%Performing iteration 6, thread count is 7.
%Performing iteration 7, thread count is 8.
%Generating output latex tables...
%File 'bench_sched_thread.tex' successfully generated! :-)
%
%Execution time: 2961.464582 seconds.
%\end{verbatim}

A Tabela~\ref{table:bench-sched-chunk} apresenta os resultados da primeira
análise. Nota-se que em todos os casos, o tamanho de \textit{chunk} ótimo foi
1.  Isso contrariou as expectativas, pois esperava-se obter como tamanho ótimo
para o \textit{chunk} um valor que se aproximasse do tamanho da \textit{cache},
para se beneficiar do \emph{alinhamento de cache}~\cite{class-notes}. Além
disso, observa-se que o escalonamento estático apresenta desempenho médio
superior ao dinâmico e ao guiado, e que o impacto de desempenho provocado pela
leitura dos dados é irrisório, sendo em média inferior à 0.1s.

\begin{table}[h!]
\footnotesize
\centering
\caption{Tamanho de \textit{chunk} variável e número de \textit{threads} fixo (em 4).}
\label{table:bench-sched-chunk}
\input{./bench_sched_chunk.tex}
\end{table}

A Tabela~\ref{table:bench-sched-thread} apresenta os resultados da segunda
análise. Observa-se dois valores aparentemente absurdos de tempo de resposta com
escalonamento dinâmico e uma \textit{thread}: 680.678471s e 680.679593s. No
entanto, esses valores apareceram nos resultados porque o \textit{laptop}
``dormiu'' devido à inatividade enquanto executava o algoritmo.

\begin{table}[h!]
\footnotesize
\centering
\caption{Tamanho de \textit{chunk} fixo (em 256) e número de \textit{threads}
variável.}
\label{table:bench-sched-thread}
\input{./bench_sched_thread.tex}
\end{table}

O \textit{speedup} de um programa paralelo é definido como~\cite{main-book}:

$$S = \frac{T_{serial}}{T_{parallel}}$$

Por motivos de simplificação, a Tabela~\ref{table:speedup} apresenta a relação
entre o \textit{speedup} obtido e o número de \textit{threads} executadas apenas
para o escalonamento estático, uma vez que as outras políticas apresentaram
ganhos similares. Observa-se que ao se utilizar duas \textit{threads} foi
possível obter um ganho significativo de desempenho ($\approx 72\%$). A partir
de três \textit{threads} o ganho sofreu atenuação e manteve uma certa
uniformidade. Acredita-se que esse comportamento ocorreu devido as
características do processador utilizado (vide Seção~\ref{sec:hardware}), que só
possui 2
\textit{cores}.

\begin{table}[h!]
\footnotesize
\centering
\caption{\textit{Speedup} x \textit{threads}.}
\label{table:speedup}
\begin{tabular}{@{}cccccccc@{}}
\toprule
\textit{Threads} & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\ \midrule
\textit{Speedup} & 0.717707 & 0.548823 & 0.564227 & 0.573196 & 0.580434 & 0.567042 & 0.581778 \\ \bottomrule 
\end{tabular}
\end{table}


\section{Conclusão}
Este trabalho possibilitou uma maior compreensão acerca da biblioteca OpenMP e
sobre algumas das dificuldades encontradas no contexto de programação paralela.
O algoritmo \textit{count sort} foi otimizado a partir da aplicação de técnicas
de programação para um maior aproveitamento dos recursos computacionais que
levaram a ganhos de desempenho. Uma análise dos tempos de execução do algoritmo
evidenciou ganhos de desempenho (\textit{speedup}) de até 72\% em relação à
versão sequencial.

Por fim, é válido ressaltar que o programa está todo parametrizado via diretivas
de pré-processamento (\texttt{\#define}) e aceita parâmetros de configuração em
tempo de execução, possibilitando a experimentação com diferentes entradas para
o algoritmo. Além disso, o \textit{design} da aplicação permite variar de forma
fácil a política de escalonamento, o tamanho dos \textit{chunks} e a quantidade
de \textit{threads} a serem executadas de forma não intrusiva, e favorece a
inclusão de novas funções de \textit{benchmarking} de forma modular.

\bibliographystyle{plain}
\bibliography{references.bib}

\end{document}








